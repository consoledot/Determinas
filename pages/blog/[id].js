import Head from "next/head";
import Image from "next/image";
import Footer from "../../components/Footer";
import Navigation from "../../components/Navigation";
import TalentPool from "../../components/Talent Pool";
import search from "../../public/images/search.svg";
import arrow_right from "../../public/images/arrow-right.svg";
import image from "../../public/images/blog-image.png";
import post1 from "../../public/images/post-1.png";
import post2 from "../../public/images/post-2.png";
import post3 from "../../public/images/post-3.png";
import post4 from "../../public/images/post-4.png";

export default function BlogPage() {
  return (
    <div>
      <Head>
        <title>Blog</title>
        <meta name="description" content="Generated by create next app" />
        <link rel="icon" href="/favicon.ico" />
      </Head>
      <Navigation />
      <header
        style={{
          backgroundImage: "url('/images/blog-header.png')",
          backgroundPosition: "center",
          backgroundSize: "cover",
        }}
      >
        <div className="header-text-body">
          <div>
            <h1>MODEL FITTING AND GENERALIZATION</h1>
            <p>
              We love to share our insights on the latest in digital
              transformation. Read our blog.
            </p>
          </div>
        </div>
      </header>
      <section className="blog-search">
        <div className="input-div">
          <input placeholder="Search for a Topic..." />
          <button>
            <Image src={search} alt="" />
          </button>
        </div>
        <div>
          <p>SUBSCRIBE TO OUR NEWSLETTER</p>
          <div className="input-div">
            <input placeholder="Enter an E-mail Address..." />
            <button>
              <Image src={arrow_right} alt="" />
            </button>
          </div>
        </div>
      </section>
      <div className="blog-page">
        <section>
          <h3>Introduction</h3>
          <p>
            The goal of building a machine learning model (especially in
            classification problems) is to capture the underlying patterns in
            the training data and predict the outcome of a new observation.
            Building a model requires training and testing data. The model is
            initially built on training data, mapping its features with the
            target variable. Afterwards, the model’s performance is evaluated
            with the test data. <br />
            It is important not to get carried away by high accuracy scores by
            our models. A model that looks too perfect is not to be trusted.
            This introduces the concept of Generalization.
          </p>
          <h3>Generalization</h3>
          <p>
            The data we collect is incomplete and noisy. It is imperative that
            the patterns learned by our machine learning model applied to
            specific examples that are not seen by the model during training.
            This is the concept of Generalization, which is a fundamental
            concept in data science. Generalization is the property of a data
            mining procedure or modelling process whereby the model applies to
            data that was not used in building the model. It is an important
            concept in data science because the goal of a good machine learning
            model is to perform well from the training data to any data from the
            problem domain that has not been seen by the model before.
          </p>
          <Image src={image} alt="" />
          <h3>Terms used in Model Generalization</h3>
          <p>
            When we talk about how well a machine learning model generalizes to
            unseen data, we use the terminologies: underfitting, overfitting,
            variance, bias and ensembles.
          </p>
          <h4>Underfitting:</h4>
          <p>
            A model is said to be underfitting when it cannot capture the
            underlying patterns of the data. This means our model does not fit
            the data well enough. Underfitting occurs when we try to use less
            data to build an accurate model. Which leads to a poorly performing
            model with little accuracy. An example of underfitting is attempting
            to build a linear model with non-linear data. <br />
            Two ways to avoid underfitting are to use data that better maps the
            input to target variables and building more complex models by adding
            more features.
          </p>
          <h4>Bias:</h4>
          <p>
            Most times the nature of our training data causes a skew in our
            model results. Bias is the average squared difference between the
            predicted values and the true values. A low bias means that on
            average, your model captures the true data generating process. A
            high bias may suggest that the model is underfitting. The main
            difference between bias and underfitting is that the training data
            still has the capacity to learn and can be corrected by making the
            model more flexible.
          </p>
          <h4>Overfitting:</h4>
          <p>
            Overfitting is when a machine learning model knows the training data
            too well that it memorizes the noises idiosyncratic to the training
            data to the extent that it drastically affects the model’s
            performance when faced with new observations. The more complex a
            data mining procedure is the higher possibility of overfitting.
            Overfitting is widely popular in applied machine learning and is a
            problem because the purpose of most machine learning models focus on
            seeing how they perform on unseen data.
            <br /> All modelling procedures have a tendency to overfit at some
            point. This is because building complex models let us capture the
            complexities of our data better hence becoming more accurate. When a
            model is not complex enough, there is a risk of underfitting which
            makes the model’s performance quite inaccurate, but as the model
            gets too complex they tend to be too accurate but are in fact
            overfitting.
          </p>
          <h4>Variance:</h4>
          <p>
            The variance measures the model’s tolerance range to new data. Low
            variance means that our model does well in generalizing. A high
            variance indicates over-fitting.
          </p>
          <h3>CONTROLLING OVERFITTING</h3>
          <h4>Cross-Validation:</h4>
          <p>
            The common approach for training and testing a machine model is to
            have a training data and a holdout data (test data) in the ratio 70%
            — 80% for training the model and 20% — 30% for testing the
            performance of the trained model. Cross-validation is a more
            intelligent use of a holdout set. It computes estimates overall data
            by performing multiple splits into subsets and using every subset
            for testing. <br />
            K-fold cross-validation is the most popular cross-validation
            technique. The procedure has a single parameter which is called K,
            which refers to the number of subsets in which a dataset is to be
            split into K-folds. For instance, K = 5 becomes a 5-Fold
            Cross-Validation. We can compute the average performance and
            standard deviation of our model performance across all subsets. The
            standard deviation gives the confidence interval of our
            performance.K-fold cross-validation technique gives us a more
            realistic estimate of our model’s performance. The figure below
            shows a 5 — fold cross-validation. <br />
            Each partition, in turn, served as a single holdout set while the
            other four were used collectively for training. Feature selection:
            Another way to control overfitting is by feature selection. This can
            be done manually if attributes are reasonably few, but with very
            large sets of attributes, it is a common approach to employ
            automatic feature selection. Ensembles: Ensembles are a way to
            introduce generality to a model. Ensembles are made of independent
            models (known as experts) trying to solve the same problem. They
            have been observed to improve generalization performance in many
            situations. The aggregation of the model is used for deriving final
            results.
          </p>
          <h3>MEASURING GENERALIZATION</h3>
          <p>Learning curves & Fitting graphs</p>
          <p>
            Remember that our goal for most data mining procedures is to access
            how well they generalize to unseen cases.
            <br /> How can we tell just when a model is appropriately fitting
            and not overkilling it? This leads us to two important plots in
            machine learning modelling:
          </p>
          <p>
            <span>Fitting graph: </span> A Fitting graph shows the difference
            between a model’s accuracy on the training data and the accuracy on
            the holdout data as the model’s complexity changes. Fitting graphs
            are shown for a fixed amount of data.
          </p>
          <p>
            <span>Learning curve: </span>A learning curve is the plot of the
            generalization performance against the amount of training data.
            Generalization performance of data-driven models generally improves
            as more training data becomes available. The curve starts out steep
            as the model finds regularities in the dataset. But as more data is
            added, the model gets more accurate until it gets to a point where
            the marginal advantage of having more data decreases.
          </p>
          <h3>Conclusion</h3>
          <p>
            Training a model too hard on a particular data causes it to pick up
            noises associated with the dataset, thereby making it perform poorly
            when faced with new data. It is important we know when to tune our
            models to the right spot. <br />
            Some ways to increase generalization of our models include
            cross-validation, feature selection and the ensemble of simple
            models.
          </p>
        </section>
        <aside>
          <div>
            <h3 className="gray-header">Structure:</h3>
            <p>Introduction</p>
            <p>Generalization</p>
            <p>Terms used in Model Generalization</p>
            <p>Controlling Overfitting</p>
            <p>Measuring Generalization</p>
            <p>Conclusion</p>
          </div>
          <div>
            <h3 className="aside-header">SEE OUR MOST RECENT ARTICLES</h3>
            <div>
              <Image src={post1} alt="" />
              <span>
                <p>Lorem Ipsum Dolor Sit Amen</p>
                <p>Machine Learning</p>
              </span>
            </div>
            <div>
              <Image src={post2} alt="" />
              <span>
                <p>Lorem Ipsum Dolor Sit Amen</p>
                <p>Product Design</p>
              </span>
            </div>
            <div>
              <Image src={post3} alt="" />
              <span>
                <p>What is Artificial Intelligence?</p>
                <p>Artificial Intelligence</p>
              </span>
            </div>
            <div>
              <Image src={post4} alt="" />
              <span>
                <p>Artificial Intelligence in the Health Care Sector</p>
                <p>Healthcare</p>
              </span>
            </div>
          </div>
          <div>
            <h3 className="aside-header">EXPLORE OUR TOPIC CATEGORIES</h3>
            <p>Telecommunications</p>
            <p>Healthcare</p>
            <p>Education</p>
            <p>E-Commerce</p>
            <p>Agriculture</p>
            <p>Transport and Logistics</p>
            <p>Banking and Finance</p>
            <p>Manufacturing</p>
            <p>Energy</p>
          </div>
          <TalentPool />
        </aside>
      </div>
      <Footer />
    </div>
  );
}
